# 기획

`감정 분석을 통한 음악 선곡과 무드 트래커 제공 서비스 제공`

> 무드트래커(MOOD TRACKER)란? 기분(MOOD)과 추적(TRACKER)의 합성어로 자신의 감정을 인식하고 추적하여 스스로 기분을 점검할 수 있도록 하는 활동입니다.

- [오늘/어제/한달 전]에 어떤 기분이었는지는 기억하기 어렵다.
- 사용자의 얼굴 사진을 입력 받아 학습시킨 딥러닝 모델로 감정을 분류하고 기록하여 시각화해주는 서비스
- 해당 감정과 관련된 노래를 선곡해주는 서비스
- 로그인을 통해 자신만의 기록을 열람할 수 있게 구현. 사진 업로드, 감정 분석 결과, 음악 매칭, 무드 트래커가 어우러진 다이어리 컨셉의 감성적인 GUI 구성

## 목적

### 1. 공익

- 증가하는 우울증, 자살, 고독사. 우리의 감정을 기록하고 되돌아 보자. 감정 상태를 기록하면 우울이나 불안 같은 부정적 감정을 식별하고 조절하는 데 도움이 된다.
- 코로나로 인해 마스크를 항상 쓰고 다니게 되면서 타인의 표정도 알 수 없고 내가 어떤 표정인지도 알기 어려워졌다. 자신의 표정을 업로드 함으로써 어떤 표정이었는지, 어떤 감정상태인지 파악할 수 있다.
- 감정에 부합하는 음악을 제공하여 멘탈케어에 도움을 준다.
- 감정을 기록하는 것을 통해 사용자의 상태를 확인할 수 있다. 구청이나 복지 단체에서 독거 노인이나 사회적 취약 계층 사람들의 감정 상태를 확인하고 무사히 계신지 확인할 수 있다.

### 2. 상업

- 코로나로 인해 식당, 카페, 매장에서 체온을 재기위해 체온계 카메라에 얼굴을 인식시키는데, 손님의 감정 상태를 체크하여 매장에 재생할 음악을 선택할 수 있다.
- 음악 추천 시스템을 이용하여 음악 회사에게 돈을 받고 음악 광고를 해주고 수익을 얻을 수 있다.
- 음악 스트리밍 사이트와 연계하여 표정에 따라서 음악을 스트리밍 할 수 있다.



# 모델 학습

- 얼굴 사진을 입력 받아 감정 상태를 출력하는 모델을 만들어야 한다.
- 이미지 분류에서 주로 사용되는 합성곱신경망(CNN) 기반으로 학습하였다.
- 학습에 사용할 데이터는 프로젝트의 프로젝트 기간, 인적 자원, 금전적 자원의 한계를 고려하여 직접 생산하기보다 최대한 정제되어있는 데이터를 구하여 사용하기로 했다. 그래서 AI허브에서 제공하는 한국인의 얼굴 이미지 데이터를 사용하였다. 



## 전처리

### 분류 클래스

AI허브에서 제공한 데이터에는 총 7개의 클래스(기쁨, 분노, 슬픔, 불안, 중립, 상처, 당황)로 분류되어있었으나 상처를 제외하기로 하였다. 왜냐하면

- 몇 번의 학습을 시도해본 결과 상처의 정확도가 다른 클래스에 비해 낮게 나왔다.
- 상처가 다른 감정들과 구분되는 뚜렷한 특징이 없는 듯하다. 상처입으면 기쁘진 않겠지만, 분노할 수도, 슬플 수도, 불안할 수도 있을 것 같다. 상처 클래스로 라벨링 된 사진을 봐도 분노에서도, 슬픔에서도, 당황에서도 봤던 사진 같다는 의아한 느낌이 든다.

따라서 6개의 클래스로 분류하는 모델을 만들 것이다.

### 이미지에서 얼굴 crop

- openCV 사용하여 시도해봤으나 부정확하게 crop되는 경우가 자주 발생했다.
- 그래서 AI허브에서 제공하는 json파일의 좌표값을 사용하였다.

### input size

- crop한 이미지 데이터의 size의 height와 width의 평균을 계산해보니 각각 1100, 820이었다. 원본 이미지는 고화질이어서 학습 시간이 많이 소요될 것으로 여겼다. 하드웨어 성능의 한계를 고려하여 height와 width를 1/4 하여 input size를 (275, 205)로 정하였다.
- keras의 ImageDataGenerator를 사용하여 이미지를 input size로 resize했다.



## 모델링

### 전이학습

> 다음을 검토하여 선정하였다.
>
> - SOTA ImageNet 분류 문제 순위
> - keras에서 지원하는지 여부
> - 가용 하드웨어가 감당할만한 크기의 모델인지

- VGG16
- Xception
- resnet50
- alexnet

이 네가지 모델을 import 하여 각각 학습을 진행하고 각 모델의 결과값의 가중 평균을 최종 결과값으로 하는 ensemble을 시도했다. 

### fine tuning

처음에는 import한 모델의 성능이 강력할 것이라 여겨 import한 모델의 파라미터를 훼손하지 않고자 결과 출력층 전의 1~2개 층만 동결을 해제 했었다. 그러나 실험 결과 합성곱층의 절반 가까이 동결을 해제했더니 학습시간이 증가하긴 했지만 정확도가 개선되었다.

### optimizer

optimizer는 『케라스 창시자에게 배우는 딥러닝』의 저자 프랑소와 숄레가 `rmsprop`을 사용하는 게 가장 좋다고 하였다. 그리고 수강했던 딥러닝 강의에서는 `adam`을 사용하였다. 그래서 그 두 가지를 사용하여 모델 학습을 시켜보았고, 둘 사이에 뚜렷한 정확도 차이는 보이지 않았다.

### batch_size

작게 할수록 학습 시간은 길어지지만 정확도는 개선됐다.

### callback

- Callback을 사용해 validation loss를 moniotor하여 validation loss가 최저인 모델을 저장했다.

- 그리고 epoch가 일정 횟수 이상 진행될 동안 validation loss가 개선되지 않으면 learning rate를 줄이도록 설정했다.

### overfitting

과적합을 줄이기 위해 regulation을 사용하였다.

- image augmentation을 사용하면 학습 소요 시간이 길어지긴 했지만, 정확도가 개선되었다.

- 무작위로 층의 일부 출력 특성을 제외하는 dropout layer를 사용하여 과적합을 줄였다.

과적합이 될수록 예측값을 극단적으로 산출했다. 각 감정별 확률을 설득력있게 산출하는 모델을 만들고 싶었기에 validation loss를 monitor하여 best 모델을 저장하는 callback을 설정하여 정확도가 높은 모델보다는 validation loss가 낮은 모델을 우선 선택했다.

### ensemble

- resnet50 모델의 정확도가 높아서 가중치를 높게 설정했다.
- 여러 가중치를 실험해본 결과 resnet50(0.3), vgg-16(0.25), Xception(0.2), alexnet(0.25)가 가장 높은 정확도를 나타냈다.  

## 결과

### validation: loss / accuracy 

VGG16: 0.8344 / 0.7004

Xception: 0.9072 / 0.6842

resnet50: 0.9213 / 0.7287

alexnet: 0.7719 / 0.6982

ensemble(25:20:30:25): 0.7219 / 0.7533

### Confusion Matrix

![confusion_matrix_heatmap](C:\Users\USER\Final_Project\image\confusion_matrix_heatmap.png)

![classification_report](C:\Users\USER\Final_Project\image\classification_report.png)

- Confusion Martix를 통해 클래스별 precision과 recall을 확인하였다. unrest가 다른 클래스에 비해 f1-score가 낮게 나왔다.
- unrest의 f1-score를 0.5 이상으로 높이는 것을 목표로 하이퍼파라미터 튜닝과 ensemble을 시도하였다. 그 결과 unrest의 f1-score 0.51을 달성하였다.

### test

최종적으로 ensemble 모델을 사용하여 test를 했다.

test Loss: 0.69735

test Accuracy: 0.7568



## 정성평가

![sad_neu](https://github.com/seosztt/project_MOOD_TRACKER/blob/master/image/sad_neu.png?raw=true)![sad_neu](https://github.com/seosztt/project_MOOD_TRACKER/blob/master/image/sad_new_result.png?raw=true)

- AI허브에서 제공 받았을 때 이 사진은 sad로 labeling되어있었다. 그러나 이 사진의 표정이 어떤 감정을 나타내는지는 사람에게 물어도 뚜렷하게 대답하기 어렵다. 이 표정이 어떤 감정을 나타내는지 모든 사람이 동의하는 객관적 답은 없을 것이다. 학습시킨 모델이 출력하는 결과값을 보아도 happy를 제외한 모든 감정에 5%이상의 확률을 나타낸다.
- AI허브에서 제공한 labeling에 따른 정확도를 높히는 것을 목표로 했다. 그러나 사람마다 답이 다른 이런 문제에서 AI허브에서 제시한 답이 꼭 보편적으로 설득력 있는 답이라고 말하기는 어렵기에 예측값이 제시한 각 감정별 확률이 그럴싸하게 느껴지면 설득력 있는 모델이라고 생각할 수도 있겠다. 그러나 이것은 느낌에 의존하므로 정성평가이다.



# 음악 선곡

- 모든 음악은 긍정적인 효과가 있고, 슬픈 상황일 때조차, 슬픈 음악을  듣는 것이 감정 완화에 효과적이라 한다. 따라서 감성 상태에 부합하는 키워드에 해당하는 음악을 선곡했다.

- 저작권 문제로 클래식을 주로 선곡했다.

- 유튜브 API를 이용하여 동영상을 재생하는 형식으로 음악을 제공하였다.



# 향후 개선 사항

- 『케라스 창시자에게 배우는 딥러닝』 책에서 저자는 앙상블 모델의 가중치를 찾기위해 넬더 미드 방법 같은 최적화 알고리즘을 사용해볼 것을 제안하였으나 사용하지 못했다.
- 이미지의 어느 부분이 컨브넷의 최종 분류 결정에 기여하는지 이해하기 위해 히트맵을 그려보고 싶었으나 코드에 에러가 발생하였다. 
- 음악 선곡을 단순 매핑이 아닌 추천 시스템을 공부하여 구현하고 싶었으나 시간 제한으로 인해 하지 못했다.



# 후기

딥러닝 모델링을 실습해볼 수 있었습니다. IT기술이 공익에 어떻게 기여할 수 있을까 고민해볼 수 있었습니다. 유쾌하고 성실한 팀원들 덕분에 무탈히 마칠 수 있게 되어 감사하게 생각합니다.

